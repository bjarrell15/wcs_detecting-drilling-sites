# -*- coding: utf-8 -*-
"""SkyTruth_UNETModel_WellpadDetection_WorkInProgress

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hNNYklJiCeXwx5duXohwIzakADfUf7Yu

# Imports and Authorizations
"""

import tensorflow as tf
from google.colab import drive
from datetime import date
import matplotlib.pyplot as plt
import numpy as np
import os

# Today's date.
today = str(date.today())

drive.mount('/content/gdrive')

"""# Get Training, Validation Data ready for UNET"""

# Bands included in our input Feature Collection and S2 imagery.

bands = ['R','G','B']
label = 'Label'
featureNames = bands + [label]
# Convert band names into tf.Features.
cols = [
          tf.io.FixedLenFeature(shape=[256,256],dtype=tf.float32) for band in featureNames
        ]
"""Pass these new tensors into a dictionary, used to describe pieces of 
   the input dataset."""
featsDict = dict(zip(featureNames,cols))

"""Parse the feature tensors made in the previous block to each tensor 
   in the input file."""
def parse_tfrecord(ex):
  return tf.io.parse_single_example(ex,featsDict)

# Converts parsed tensors to tuples of (RGB, masks).
def to_tuple(inputs):
  inputsList = [inputs.get(key) for key in featureNames]

  """Packs the list of tensors in values into a tensor with rank one higher 
     than each tensor in values, by packing them along the axis dimension."""
  stacked = tf.stack(inputsList,axis=0)
  # Takes [z,x,y] 3-D array and transposes it to [x,y,z].
  stacked = tf.transpose(stacked,[1,2,0])
  # First portion of tuple: [all of X, all of Y, 3 deep (i.e. "R","G","B")].
  # Second portion of tuple: [all of X, all of Y, 1 deep (i.e. the binary mask, called "Label" here)].
  return stacked[:,:,:len(bands)], stacked[:,:,len(bands):]

# Convert the band values to percentages, perform data augmentation.
def resize(image,mask):
  newTensor = image / 4096.0 #for S2.
  # newTensor = img / 255.0 #for NAIP.
  
  rand = np.random.randint(100)
  
  if rand < 20:
    newTensor = tf.image.flip_left_right(newTensor)
    mask = tf.image.flip_left_right(mask)

  elif rand >= 20 and rand < 40:
    newTensor = tf.image.rot90(newTensor)
    mask = tf.image.rot90(mask)

  elif rand >= 40 and rand < 60:
    newTensor = tf.image.flip_up_down(newTensor)
    mask = tf.image.flip_up_down(mask)

  elif rand >= 60 and rand < 80:
    newTensor = tf.image.adjust_saturation(newTensor, 1)
    mask = mask

  else:
    pass

  return (newTensor, mask)

# Load in dataset, map helper functions defined above to each tensor.
def get_dataset(pattern):
  # Note: "pattern" could also be a list of TFRecords.
  # Uses absolute paths specified in "pattern" to glob together all the input 
  # TFRecords. 
  # From Python docs: "The glob module finds all the pathnames matching a specified pattern".
  glob = tf.io.gfile.glob(pattern)
  # Moves all of the TFRecords into an in-memory TFRecordDataset, which is then primed for 
  # preprocessing.
  ds = tf.data.TFRecordDataset(glob,compression_type='GZIP')
  # The next three lines map the helper functions defined above to the TFRecordDataset.
  ds = ds.map(parse_tfrecord,num_parallel_calls=5)
  ds = ds.map(to_tuple,num_parallel_calls=5)
  ds = ds.map(resize,num_parallel_calls=5)
  return ds

# Load in our dataset, shuffle the input features.
dir = '/content/gdrive/My Drive/detecting_drilling_sites/data/trainingData/new_training_sites_s2'

files = os.listdir(dir)
files = [f'{dir}/{fn}' for fn in files]
data = get_dataset(files).shuffle(5000)

# test = get_dataset('/content/gdrive/My Drive/detecting_drilling_sites/data/Penn17_merged.tfrecord.gz').shuffle(1000)

# Visualize a member of dataset.
def show(image, mask):
  plt.figure()

  plt.subplot(1, 2, 1)
  plt.imshow(tf.keras.preprocessing.image.array_to_img(image))
  plt.axis('off')

  plt.subplot(1, 2, 2)
  plt.imshow(tf.squeeze(mask))
  plt.axis('off')

for img, msk in data.take(2):
  show(img,msk)

# Get the full size of the dataset.
full_size = len(list(data))
print(f'Full size of the dataset: {full_size}','\n')

# Define a split for the dataset.
train_pct = 0.7
batch_size = 16
split = int(full_size * train_pct)

# Split it up.
training = data.take(split)
evaluation = data.skip(split)

# Get the data ready for inference.
training = training.shuffle(split).batch(batch_size).repeat()
evaluation = evaluation.batch(batch_size)

# Define the steps taken per epoch for both training and evaluation.
TRAIN_STEPS = int(split / batch_size)
EVAL_STEPS = int((full_size - split)  / batch_size)

print(f'Number of training steps: {TRAIN_STEPS}')
print(f'Number of evaluation steps: {EVAL_STEPS}')

"""# Build the model here"""

# Import necessary keras modules.
# Load TensorFlow modules: layers, models, etc. 
from tensorflow.keras import layers, losses, metrics, models, optimizers, regularizers, backend

# Screens to be passed over the image in the model.
filt = [16,32,64,128,256]

# Functions associated with the UNET architecture.
def downward_conv(inputTensor, numFilters, act = 'relu', p = 'same'):
  down = layers.Conv2D(filters = numFilters, kernel_size = (3,3), strides = 1, padding = p)(inputTensor)
  down = layers.BatchNormalization()(down)
  down = layers.Activation(act)(down)
  down = layers.Dropout(0.2)(down)
  down = layers.Conv2D(filters = numFilters, kernel_size = (3,3), strides = 1, padding = p)(down)
  down = layers.BatchNormalization()(down)
  down = layers.Activation(act)(down)
  down = layers.Dropout(0.2)(down)
  pool = layers.MaxPool2D(pool_size = (2,2), strides = (2,2))(down)
  return down, pool

def bottleneck(inputTensor, numFilters, act = 'relu', p = 'same'):
  mid = layers.Conv2D(filters = numFilters, kernel_size = (3,3), strides = 1, padding = p)(inputTensor)
  mid = layers.BatchNormalization()(mid)
  mid = layers.Activation(act)(mid)  
  mid = layers.Dropout(0.2)(mid)
  mid = layers.Conv2D(filters = numFilters, kernel_size = (3,3), strides = 1, activation = act, padding = p)(mid)
  mid = layers.BatchNormalization()(mid)
  mid = layers.Activation(act)(mid)
  mid = layers.Dropout(0.2)(mid)
  return mid

def upward_conv(inputTensor, correspondingDownTensor, numFilters, act = 'relu', p = 'same'):
  up = layers.Conv2DTranspose(filters = numFilters, kernel_size = (2,2), strides = (2,2), padding = p)(inputTensor)
  up = layers.concatenate([correspondingDownTensor,up],axis=-1)
  up = layers.Activation(act)(up)
  up = layers.Conv2D(filters = numFilters, kernel_size = (3,3), strides = 1, padding = p)(up)
  up = layers.BatchNormalization()(up)
  up = layers.Activation(act)(up)
  up = layers.Dropout(0.2)(up)
  up = layers.Conv2D(filters = numFilters, kernel_size = (3,3), strides = 1, padding = p)(up)
  up = layers.BatchNormalization()(up)
  up = layers.Activation(act)(up)
  up = layers.Dropout(0.2)(up)
  return up

def unet():
  start = layers.Input(shape = ([256, 256, 3]))   
  down_step1, pool1 = downward_conv(start, filt[0])
  down_step2, pool2 = downward_conv(pool1, filt[1])
  down_step3, pool3 = downward_conv(pool2, filt[2])
  down_step4, pool4 = downward_conv(pool3, filt[3])

  middle = bottleneck(pool4, filt[4])

  up_step1 = upward_conv(middle, down_step4, filt[3])
  up_step2 = upward_conv(up_step1, down_step3, filt[2])
  up_step3 = upward_conv(up_step2, down_step2, filt[1])
  up_step4 = upward_conv(up_step3, down_step1, filt[0])

  output = layers.Conv2D(filters = 1, kernel_size = (1,1), activation = 'sigmoid', padding = 'same')(up_step4)
  
  model = models.Model(inputs = start, outputs = [output])
  def dice_coeff(y_true, y_pred):
      smooth = 1.
      # Flatten
      y_true_f = tf.reshape(y_true, [-1])
      y_pred_f = tf.reshape(y_pred, [-1])
      intersection = tf.reduce_sum(y_true_f * y_pred_f)
      score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)
      return score

  def dice_loss(y_true, y_pred):
      loss = 1 - dice_coeff(y_true, y_pred)
      return loss
  
  def bce_dice_loss(y_true, y_pred):
    loss = losses.binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)
    return loss

  model.compile(
      optimizer='adam',
      loss=bce_dice_loss,
      metrics=[dice_loss])
  
  return model

UNet = unet()

tf.keras.utils.plot_model(UNet,show_shapes=True)

"""# Train the model"""

def augmentation(img, msk):

  # Call in skimage package, which will be used for transformations.
  import tensorflow.math as Math

  # Create some random floats, which will be used in augmentation steps.
  tilt = tf.random.uniform(shape = [], minval = -30, maxval = 30, dtype = tf.float32)
  dx = tf.random.uniform(shape = [], minval = -5, maxval = 5, dtype = tf.float32)
  dy = tf.random.uniform(shape = [], minval = -5, maxval = 5, dtype = tf.float32)

  # Use TensforFlow-style if conditionals, used to flip image and mask.
  img = tf.cond(tilt > 0, lambda: tf.image.flip_left_right(img), lambda: tf.image.flip_up_down(img))
  msk = tf.cond(tilt > 0, lambda: tf.image.flip_left_right(msk), lambda: tf.image.flip_up_down(msk))

  # Rotate the image and mask to some degree.
  # img = rotate(img, angle = tilt, mode = 'reflect')
  # msk = rotate(msk, angle = tilt, mode = 'reflect')
  toRads = Math.multiply(Math.divide(tilt,180),tf.constant(math.pi))

  img = tfa.image.rotate(img, toRads)
  msk = tfa.image.rotate(msk, toRads)
 
  # Affine transformation
  img = tfa.image.translate(img, [dx,dy], 'BILINEAR')
  msk = tfa.image.translate(msk, [dx,dy], 'BILINEAR')

  # Convert the inputs back into tensors, put back into a tuple.
  finalTuple = (img, msk)

  return finalTuple

# Callback for data augmentation.
class aug(tf.keras.callbacks.Callback):
  def on_training_batch_begin(self, batch, logs = None):
    batch.map(augmentation, num_parallel_calls = 5)
    batch.shuffle(10)
    
# Trying early stopping on 07/22.
earlyStopper = tf.keras.callbacks.EarlyStopping(patience=5, verbose=1)

save_model_path = f'/content/gdrive/My Drive/{today}_wellpad_model.h5'
cp = tf.keras.callbacks.ModelCheckpoint(filepath=save_model_path,
                                        monitor='val_dice_loss',
                                        mode='min',
                                        save_best_only=True)

# Sanity check
test_batch = evaluation.shuffle(100).take(1)

test_batch = test_batch.map(augment,num_parallel_calls=5)

test_batch = [(image,mask) for image, mask in test_batch]

plt.figure(figsize=(10,10))
plt.subplot(1,2,1)
# Show the original image.
plt.imshow(test_batch[0][0][0])
# Show the masked image.
plt.subplot(1,2,2)
plt.imshow(tf.squeeze(test_batch[0][1][0]))

# Set number of epochs over which to fit the model here.
model_epochs = 100

# Let's give it a go.
history = UNet.fit(
      x = training,
      epochs = model_epochs,
      steps_per_epoch = TRAIN_STEPS,
      validation_data = evaluation,
      validation_steps = EVAL_STEPS,
      callbacks = [aug(),cp])

UNet.save(f'/content/gdrive/My Drive/{today}_wellpad_model.h5')

training_acc = history.history['dice_loss']
validation_acc = history.history['val_dice_loss']

training_loss = history.history['loss']
validation_loss = history.history['val_loss']

epochs = range(1, model_epochs+1)
plt.figure(figsize = (8,8))

plt.plot(epochs, training_acc, 'bo', label='Training Metric')
plt.plot(epochs, validation_acc, 'ro', label='Validation Metric')
plt.title('Training and validation metrics (Dice Loss)')
plt.legend()

plt.figure(figsize = (8,8))
plt.plot(epochs, training_loss, 'b', label='Training loss')
plt.plot(epochs, validation_loss, 'r', label='Validation loss')
plt.title('Training and validation loss (BCE + Dice)')
plt.legend()

plt.show()

"""#If model has already been run, load it here..."""

# UNet = models.load_model('/content/gdrive/My Drive/detecting_drilling_sites/data/2020-07-20_wellpad_model.h5') # Enter the date of the model you'd like to run.

def dice_loss(y_true, y_pred):
    loss = 1 - dice_coeff(y_true, y_pred)
    return loss
  
def bce_dice_loss(y_true, y_pred):
  loss = losses.binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)
  return loss

UNet = models.load_model('/content/gdrive/My Drive/2020-07-31_wellpad_model.h5',
                         custom_objects = {'dice_loss':dice_loss,
                                           'bce_dice_loss':bce_dice_loss})

tf.keras.utils.plot_model(UNet,show_shapes=True)

"""#Perform predictions below..."""

test = evaluation.take(1).map(augment,num_parallel_calls=5)

test_images = [(img,mask) for img,mask in test]

plt.imshow(test_images[0][0][0])

test_predict = UNet.predict(test_images,verbose=1)

pred = 11

plt.figure(figsize = (15,15))

plt.subplot(2,2,1)
plt.imshow(test_images[0][0][pred])

plt.subplot(2,2,2)
plt.imshow(tf.squeeze(test_predict[pred]))
